def generate_summ_df_with_scenarios_formatted(df):
    """
    Generate summary statistics and categorize data into High, Medium, and Low Risk tiers
    based on three different scenarios, formatted as cumulative approval tables.
    
    Scenario 1:
        - High Risk: Top 10% of score distribution with reason code.
        - Low Risk: Bottom 50% of score distribution without reason code.
    
    Scenario 2:
        - High Risk: Top 15% of score distribution with reason code.
        - Low Risk: Bottom 45% of score distribution without reason code.
    
    Scenario 3:
        - High Risk: Top 20% of score distribution with reason code.
        - Low Risk: Bottom 40% of score distribution without reason code.
    
    - Medium Risk: Remaining population in all scenarios.
    """
    results = {}

    scenarios = [
        (0.10, 0.50, "Scenario 1"),
        (0.15, 0.45, "Scenario 2"),
        (0.20, 0.40, "Scenario 3")
    ]

    for high_risk_pct, low_risk_pct, scenario_name in scenarios:
        df_copy = df.copy()

        # Remove NaN values in fraud score column
        df_copy = df_copy.dropna(subset=['SIGMAFIRSTPARTYFRAUDSCORE'])

        # Identify whether a reason code is present (assuming reason codes start with R102, R103, etc.)
        reason_code_columns = [col for col in df_copy.columns if col.startswith(('R102', 'R103', 'R104'))]
        df_copy['Has_Reason_Code'] = df_copy[reason_code_columns].astype(bool).any(axis=1).astype(int)

        # Compute percentile thresholds
        high_risk_threshold = np.percentile(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'], 100 - (high_risk_pct * 100))
        low_risk_threshold = np.percentile(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'], low_risk_pct * 100)

        # Categorize risk tiers
        df_copy['Risk_Tier'] = 'Medium Risk'  # Default
        df_copy.loc[(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'] >= high_risk_threshold) & (df_copy['Has_Reason_Code'] == 1), 'Risk_Tier'] = 'High Risk'
        df_copy.loc[(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'] <= low_risk_threshold) & (df_copy['Has_Reason_Code'] == 0), 'Risk_Tier'] = 'Low Risk'

        # Aggregate statistics formatted similarly to the given output
        summ = df_copy.groupby(['Risk_Tier', 'SIGMAFIRSTPARTYFRAUDSCORE']).size().reset_index(name='total_review')
        summ['cum_tot_max'] = summ['total_review'].cumsum()
        summ['cum_approve'] = summ['total_review'].cumsum()
        summ['cum_approve_pct'] = summ['cum_approve'] / summ['cum_tot_max']

        results[scenario_name] = summ[['Risk_Tier', 'SIGMAFIRSTPARTYFRAUDSCORE', 'cum_approve_pct', 'cum_approve', 'total_review']]

    return results

# Apply the function across all datasets in df_dict
risk_scenario_formatted_results = {}
for name, df in df_dict.items():
    risk_scenario_formatted_results[name] = generate_summ_df_with_scenarios_formatted(df)

# Display results for all datasets
for dataset_name, scenario_results in risk_scenario_formatted_results.items():
    for scenario, df_result in scenario_results.items():
        import ace_tools as tools
        tools.display_dataframe_to_user(name=f"{dataset_name}_{scenario}", dataframe=df_result)

# Display results for all datasets without using ace_tools
for dataset_name, scenario_results in risk_scenario_formatted_results.items():
    for scenario, df_result in scenario_results.items():
        print(f"\nDataset: {dataset_name} - {scenario}")
        print(df_result.to_string(index=False))


import pandas as pd
import numpy as np

def generate_summ_df_with_thresholds(df):
    """
    Generate summary statistics and categorize data into High, Medium, and Low Risk tiers
    based on three different scenarios. Each scenario specifies:
    
    - High Risk: Top X% of score distribution with reason code.
    - Low Risk: Bottom Y% of score distribution without reason code.
    - Medium Risk: Remaining population.
    
    This function also calculates the score thresholds for each risk tier.
    """
    results = {}

    scenarios = [
        (0.10, 0.50, "Scenario 1"),
        (0.15, 0.45, "Scenario 2"),
        (0.20, 0.40, "Scenario 3")
    ]

    for high_risk_pct, low_risk_pct, scenario_name in scenarios:
        df_copy = df.copy()

        # Remove NaN values in fraud score column
        df_copy = df_copy.dropna(subset=['SIGMAFIRSTPARTYFRAUDSCORE'])

        # Identify whether a reason code is present (assuming reason codes start with R102, R103, etc.)
        reason_code_columns = [col for col in df_copy.columns if col.startswith(('R102', 'R103', 'R104'))]
        df_copy['Has_Reason_Code'] = df_copy[reason_code_columns].astype(bool).any(axis=1).astype(int)

        # Compute percentile thresholds
        high_risk_threshold = np.percentile(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'], 100 - (high_risk_pct * 100))
        low_risk_threshold = np.percentile(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'], low_risk_pct * 100)

        # Categorize risk tiers
        df_copy['Risk_Tier'] = 'Medium Risk'  # Default
        df_copy.loc[(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'] >= high_risk_threshold) & (df_copy['Has_Reason_Code'] == 1), 'Risk_Tier'] = 'High Risk'
        df_copy.loc[(df_copy['SIGMAFIRSTPARTYFRAUDSCORE'] <= low_risk_threshold) & (df_copy['Has_Reason_Code'] == 0), 'Risk_Tier'] = 'Low Risk'

        # Aggregate statistics
        risk_summary = df_copy.groupby('Risk_Tier').agg(
            count=('SIGMAFIRSTPARTYFRAUDSCORE', 'count'),
            avg_score=('SIGMAFIRSTPARTYFRAUDSCORE', 'mean'),
            min_score=('SIGMAFIRSTPARTYFRAUDSCORE', 'min'),
            max_score=('SIGMAFIRSTPARTYFRAUDSCORE', 'max')
        ).reset_index()

        # Add threshold information
        risk_summary['threshold'] = risk_summary.apply(
            lambda row: f"{row['min_score']:.2f} - {row['max_score']:.2f}", axis=1
        )

        results[scenario_name] = risk_summary

    return results

# Example usage:
# Assuming df_dict is a dictionary containing your DataFrames
# risk_scenario_results = {}
# for name, df in df_dict.items():
#     risk_scenario_results[name] = generate_summ_df_with_thresholds(df)

# Display results for all datasets
# for dataset_name, scenario_results in risk_scenario_results.items():
#     for scenario, df_result in scenario_results.items():
#         print(f"\nDataset: {dataset_name} - {scenario}")
#         print(df_result.to_string(index=False))

# Save formatted results to an Excel file for easy copying and sharing
excel_filename = "/mnt/data/risk_summary.xlsx"

# Create a writer object
with pd.ExcelWriter(excel_filename, engine="xlsxwriter") as writer:
    for dataset_name, scenario_results in aggregated_results_corrected.items():
        for scenario, df_result in scenario_results.items():
            sheet_name = f"{dataset_name}_{scenario}"[:31]  # Excel sheet names are limited to 31 chars
            df_result.to_excel(writer, sheet_name=sheet_name, index=False)

# Provide the download link
excel_filename